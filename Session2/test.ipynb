{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c530a9e2",
   "metadata": {},
   "source": [
    "## K - means with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "401b1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f15f9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm         Species\n",
       "0              5.1           3.5            1.4           0.2     Iris-setosa\n",
       "1              4.9           3.0            1.4           0.2     Iris-setosa\n",
       "2              4.7           3.2            1.3           0.2     Iris-setosa\n",
       "3              4.6           3.1            1.5           0.2     Iris-setosa\n",
       "4              5.0           3.6            1.4           0.2     Iris-setosa\n",
       "..             ...           ...            ...           ...             ...\n",
       "145            6.7           3.0            5.2           2.3  Iris-virginica\n",
       "146            6.3           2.5            5.0           1.9  Iris-virginica\n",
       "147            6.5           3.0            5.2           2.0  Iris-virginica\n",
       "148            6.2           3.4            5.4           2.3  Iris-virginica\n",
       "149            5.9           3.0            5.1           1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Iris.csv\")\n",
    "df = df.drop(\"Id\", axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81db3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f25ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dfb0e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2,\n",
       "       2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters = 3).fit(x)\n",
    "y_pred = model.predict(x)\n",
    "# y_pred = y_pred.astype(str)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4335d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.sum(np.equal(y, y_pred))\n",
    "accuracy/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e97873",
   "metadata": {},
   "source": [
    "## K - means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b939a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Member():\n",
    "    def __init__(self, r_d, label = None, doc_id = None):\n",
    "        self._r_d = r_d\n",
    "        self._label = label\n",
    "        self._doc_id = doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa25ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster():\n",
    "    def __init__(self):\n",
    "        self._centroid = None\n",
    "        self._members = []\n",
    "        \n",
    "    def set_centroid(self, new_centroid):\n",
    "        self._centroid = new_centroid\n",
    "        \n",
    "    def reset_members(self):\n",
    "        self._members = []\n",
    "        \n",
    "    def add_members(self, new_member):\n",
    "        self._members.append(new_member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5315471",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans():\n",
    "    def __init__(self, num_clusters):\n",
    "        self._num_clusters = num_clusters\n",
    "        self._clusters = [Cluster() for i in range(self._num_clusters)]\n",
    "        self._E = []  # list of centroid\n",
    "        self._S = 0 # overall similarity\n",
    "        \n",
    "    def load_data(self, path = \"C:/Users/HH/OneDrive - Hanoi University of Science and Technology/ML basics/Session1/20news-bydate/\"):\n",
    "        with open(path + \"words_idf.txt\") as file:\n",
    "            vocab_size = len(file.read().splitlines())\n",
    "        \n",
    "        with open(path + \"data_tf_idf.txt\") as file:\n",
    "            content = file.read().splitlines()\n",
    "        self._data = []\n",
    "        for line in content:\n",
    "            r_d = [0.0 for i in range(vocab_size)]\n",
    "            data_line = line.split(\"<fff>\")\n",
    "            label, doc_id = int(data_line[0]), int(data_line[1])\n",
    "            indexes_and_tfidfs = data_line[2].split()\n",
    "            for index_and_tfidf in indexes_and_tfidfs:\n",
    "                index = int(index_and_tfidf.split(':')[0])\n",
    "                tfidf = float(index_and_tfidf.split(':')[1])\n",
    "                r_d[index] = tfidf\n",
    "            self._data.append(Member(np.array(r_d), label, doc_id))\n",
    "    \n",
    "    def random_init(self, seed_value):\n",
    "        random.seed(seed_value)\n",
    "        pos = np.random.choice(len(self._data), self._num_clusters, replace = False)\n",
    "        \n",
    "        centroid = []\n",
    "        for i in pos:\n",
    "            centroid.append(self._data[i]._r_d)\n",
    "        self._E = centroid\n",
    "        for i in range(self._num_clusters):\n",
    "            self._clusters[i].set_centroid(centroid[i])\n",
    "    \n",
    "    def compute_similarity(self, member, centroid):\n",
    "        return cosine_similarity([member._r_d], [centroid])\n",
    "    \n",
    "    def select_cluster_for(self, member):\n",
    "        best_fit_cluster = None\n",
    "        \n",
    "        max_similarity = -1\n",
    "        for cluster in self._clusters:\n",
    "            similarity = self.compute_similarity(member, cluster._centroid)\n",
    "            if similarity > max_similarity:\n",
    "                best_fit_cluster = cluster\n",
    "                max_similarity = similarity\n",
    "        best_fit_cluster.add_members(member)\n",
    "        return max_similarity\n",
    "    \n",
    "    def update_centroid_of(self, cluster):\n",
    "        member_r_ds = [member._r_d for member in cluster._members]\n",
    "        avg_r_d = np.mean(member_r_ds, axis = 0)\n",
    "        sqrt_mean = np.sqrt(np.sum(avg_r_d**2))\n",
    "        new_centroid = avg_r_d /sqrt_mean\n",
    "        \n",
    "        cluster.set_centroid(new_centroid)\n",
    "        \n",
    "    def stopping_condition(self, criterion, threshold):\n",
    "        criteria = [\"centroid\", \"iteration\", \"similarity\"]\n",
    "        assert criterion in criteria\n",
    "        if criterion == \"iteration\":\n",
    "            if self._iteration >= threshold:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        elif criterion == \"centroid\":\n",
    "            new_E = [cluster._centroid for cluster in self._clusters]\n",
    "            new_E_minus_E = [centroid for centroid in new_E if centroid not in E]\n",
    "            self._E = new_E\n",
    "            if len(new_E_minus_E) <= threshold:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            new_S_minus_S = self._new_S - self._S\n",
    "            self.S = self._new_S\n",
    "            if new_S_minus_S <= threshold:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    def run(self, criterion, threshold, seed_value):\n",
    "        self.random_init(seed_value)\n",
    "        self._iteration = 0\n",
    "        while True:\n",
    "            for cluster in self._clusters:\n",
    "                cluster.reset_members()\n",
    "                self._new_S = 0\n",
    "            for member in self._data:\n",
    "                max_S = self.select_cluster_for(member)\n",
    "                self._new_S += max_S\n",
    "            for cluster in self._clusters:\n",
    "                update_centroid_of(cluster)\n",
    "                \n",
    "            if stopping_condition(criterion, threshold):\n",
    "                break\n",
    "                \n",
    "    def compute_purity(self):\n",
    "        majority_sum = 0\n",
    "        for cluster in self._clusters:\n",
    "            max_label = 0\n",
    "            member_labels = [member._label for member in cluster._members]\n",
    "            all_labels = list(set(member_labels))\n",
    "            for label in all_labels:\n",
    "                max_label = max(member_labels.count(label), max_label)\n",
    "            majority_sum += max_label\n",
    "        return majority_sum * 1./len(self._data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4577fbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'update_centroid_of' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(num_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m      2\u001b[0m kmeans\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m----> 3\u001b[0m kmeans\u001b[38;5;241m.\u001b[39mrun(seed_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m      4\u001b[0m kmeans\u001b[38;5;241m.\u001b[39mcompute_purity()\n",
      "Cell \u001b[1;32mIn[11], line 95\u001b[0m, in \u001b[0;36mKMeans.run\u001b[1;34m(self, criterion, threshold, seed_value)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_S \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m max_S\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clusters:\n\u001b[1;32m---> 95\u001b[0m     update_centroid_of(cluster)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stopping_condition(criterion, threshold):\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'update_centroid_of' is not defined"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(num_clusters = 8)\n",
    "kmeans.load_data()\n",
    "kmeans.run(seed_value=42, criterion='similarity', threshold=1e-3)\n",
    "kmeans.compute_purity()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
